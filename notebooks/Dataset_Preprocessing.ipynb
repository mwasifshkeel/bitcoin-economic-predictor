{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U93zm_su3MTN",
        "outputId": "31e31ecd-5768-4982-ab80-a0cc9b4959e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 26844\n",
            "Expanded dataset size: 68000\n",
            "Results saved to 'sentiment_analysis_results.csv'\n",
            "       Sentiment Score                              News Headline Summary\n",
            "53706              1.0  CHF Retail Sales y/y reported better than expe...\n",
            "26878              1.0  EUR Italian Retail Sales m/m reported better t...\n",
            "26869              1.0  GBP Retail Sales m/m reported better than expe...\n",
            "26864              1.0  USD Empire State Manufacturing Index reported ...\n",
            "53730              1.0  EUR Retail Sales m/m reported better than expe...\n",
            "53787              1.0  CAD Employment Change reported better than exp...\n",
            "26844              1.0  USD PPI m/m reported worse than expected at -0...\n",
            "26879              1.0  EUR German Unemployment Change reported better...\n",
            "26899              1.0  GBP Retail Sales m/m reported better than expe...\n",
            "26868              1.0  CHF Retail Sales y/y reported better than expe...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "import io\n",
        "import random\n",
        "\n",
        "\n",
        "# Sample economic news data\n",
        "data_str = \"\"\"Date Time Currency Impact Event Title Actual Forecast Previous\n",
        "Apr-22 Day 2 All Medium IMF Meetings\n",
        "Apr-20 1:00am USD Medium FOMC Member Fischer Speaks\n",
        "Apr-20 3:45am NZD High CPI q/q 1.00% 0.80% 0.40%\n",
        "Apr-20 4:50am JPY Low Trade Balance 0.17T 0.61T 0.61T\n",
        "Apr-20 6:30am AUD Medium NAB Quarterly Business Confidence 6 6\n",
        "Apr-20 11:00am EUR Low German PPI m/m 0.00% 0.20% 0.20%\n",
        "Apr-20 1:50pm EUR Low Spanish 10-y Bond Auction 1.68|1.5 1.61|1.6\n",
        "Apr-20 5:30pm USD High Philly Fed Manufacturing Index 22 25.6 32.8\n",
        "Apr-20 7:00pm EUR Low Consumer Confidence -4 -5 -5\n",
        "Apr-20 7:30pm USD Low Natural Gas Storage 54B 49B 10B\n",
        "Apr-20 8:30pm GBP High BOE Gov Carney Speaks\n",
        "Apr-20 9:30pm GBP High BOE Gov Carney Speaks\n",
        "Apr-20 10:15pm USD High Treasury Sec Mnuchin Speaks\n",
        "Apr-26 1:30am USD Low API Weekly Statistical Bulletin\n",
        "Apr-26 3:45am NZD Low Visitor Arrivals m/m 1.50%   -1.90%\n",
        "Apr-26 6:30am AUD High CPI q/q 0.50% 0.60% 0.50%\"\"\"\n",
        "\n",
        "\n",
        "df = pd.read_csv('forexfactory_calendar_full.csv')\n",
        "\n",
        "# Function to normalize values and extract numeric part\n",
        "def normalize_value(value):\n",
        "    if pd.isna(value):\n",
        "        return None\n",
        "\n",
        "    # Convert to string and remove any non-numeric characters except decimal point and negative sign\n",
        "    if isinstance(value, str):\n",
        "        # Extract percentage if present\n",
        "        if '%' in value:\n",
        "            try:\n",
        "                return float(value.replace('%', '')) / 100\n",
        "            except:\n",
        "                return None\n",
        "\n",
        "        # Extract numeric part for values with T, B, etc.\n",
        "        match = re.search(r'(-?\\d+\\.?\\d*)', value)\n",
        "        if match:\n",
        "            return float(match.group(1))\n",
        "\n",
        "    try:\n",
        "        return float(value)\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Function to calculate sentiment score based on economic indicators\n",
        "def calculate_sentiment_score(row):\n",
        "    # Base sentiment score\n",
        "    score = 0\n",
        "\n",
        "    # Factor 1: Impact weighting\n",
        "    impact_weight = {'High': 0.3, 'Medium': 0.2, 'Low': 0.1}\n",
        "    if row['Impact'] in impact_weight:\n",
        "        score += impact_weight[row['Impact']]\n",
        "\n",
        "    # Factor 2: Currency importance (USD and EUR are considered more impactful)\n",
        "    currency_weight = {'USD': 0.15, 'EUR': 0.12, 'GBP': 0.1, 'JPY': 0.08, 'AUD': 0.07, 'NZD': 0.06}\n",
        "    if row['Currency'] in currency_weight:\n",
        "        score += currency_weight[row['Currency']]\n",
        "\n",
        "    # Factor 3: Actual vs Forecast comparison\n",
        "    actual = normalize_value(row['Actual'])\n",
        "    forecast = normalize_value(row['Forecast'])\n",
        "\n",
        "    if actual is not None and forecast is not None:\n",
        "        # Determine if higher or lower values are better based on the event type\n",
        "        event_title = row['Event Title'].lower()\n",
        "\n",
        "        # Generally positive indicators when higher than forecast\n",
        "        positive_indicators = ['gdp', 'consumer confidence', 'business confidence', 'manufacturing', 'employment', 'retail sales']\n",
        "        # Generally negative indicators when higher than forecast\n",
        "        negative_indicators = ['unemployment', 'deficit', 'inflation', 'cpi', 'ppi']\n",
        "\n",
        "        is_positive_indicator = any(term in event_title for term in positive_indicators)\n",
        "        is_negative_indicator = any(term in event_title for term in negative_indicators)\n",
        "\n",
        "        if is_positive_indicator:\n",
        "            # For positive indicators, higher than forecast is good\n",
        "            if actual > forecast:\n",
        "                score += 0.2 * (actual - forecast) / max(abs(forecast), 0.001)\n",
        "            else:\n",
        "                score -= 0.2 * (forecast - actual) / max(abs(forecast), 0.001)\n",
        "        elif is_negative_indicator:\n",
        "            # For negative indicators, lower than forecast is good\n",
        "            if actual < forecast:\n",
        "                score += 0.2 * (forecast - actual) / max(abs(forecast), 0.001)\n",
        "            else:\n",
        "                score -= 0.2 * (actual - forecast) / max(abs(forecast), 0.001)\n",
        "        else:\n",
        "            # For other indicators, any deviation from forecast is treated as slightly negative\n",
        "            score -= 0.1 * abs(actual - forecast) / max(abs(forecast), 0.001)\n",
        "\n",
        "    # Factor 4: Sentiment from event title text\n",
        "    title_sentiment = TextBlob(row['Event Title']).sentiment.polarity\n",
        "    score += 0.25 * title_sentiment\n",
        "\n",
        "    # Normalize score to range between -1 and 1\n",
        "    score = max(min(score, 1), -1)\n",
        "\n",
        "    # Apply randomization to extreme values\n",
        "    if abs(score) == 1.0:\n",
        "        if score > 0:\n",
        "            score *= random.uniform(0.85, 0.99)  # Randomize extreme positive values\n",
        "        else:\n",
        "            score *= random.uniform(0.85, 0.99)  # Randomize extreme negative values\n",
        "\n",
        "    return score\n",
        "\n",
        "# Function to create a summary from the event title\n",
        "def create_summary(row):\n",
        "    event = row['Event Title']\n",
        "    currency = row['Currency']\n",
        "    actual = row['Actual']\n",
        "    forecast = row['Forecast']\n",
        "\n",
        "    # For events with actual and forecast values\n",
        "    if pd.notna(actual) and pd.notna(forecast):\n",
        "        actual_val = normalize_value(actual)\n",
        "        forecast_val = normalize_value(forecast)\n",
        "\n",
        "        if actual_val is not None and forecast_val is not None:\n",
        "            if actual_val > forecast_val:\n",
        "                performance = \"better than expected\"\n",
        "            elif actual_val < forecast_val:\n",
        "                performance = \"worse than expected\"\n",
        "            else:\n",
        "                performance = \"as expected\"\n",
        "\n",
        "            return f\"{currency} {event} reported {performance} at {actual}.\"\n",
        "\n",
        "    # For events without actual/forecast values\n",
        "    return f\"{currency} {event}.\"\n",
        "\n",
        "# Apply sentiment analysis to each row\n",
        "df['Sentiment Score'] = df.apply(calculate_sentiment_score, axis=1)\n",
        "df['News Headline Summary'] = df.apply(create_summary, axis=1)\n",
        "\n",
        "# Select and format the output\n",
        "result_df = df[['Sentiment Score', 'News Headline Summary']].copy()\n",
        "result_df['Sentiment Score'] = result_df['Sentiment Score'].round(2)\n",
        "\n",
        "# Sort by sentiment score\n",
        "result_df = result_df.sort_values(by='Sentiment Score', ascending=False)\n",
        "\n",
        "# Function to create additional entries with slightly varied sentiment scores\n",
        "def expand_dataset(df, target_size=68000):\n",
        "    original_size = len(df)\n",
        "    copies_needed = target_size - original_size\n",
        "\n",
        "    if copies_needed <= 0:\n",
        "        return df\n",
        "\n",
        "    duplication_factor = int(np.ceil(copies_needed / original_size))\n",
        "\n",
        "    # Initialize an empty list to hold all rows\n",
        "    expanded_data = [df]\n",
        "\n",
        "    # Generate duplicates with variations\n",
        "    for _ in range(duplication_factor):\n",
        "        # Create a copy of the original dataframe\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        # Add random variations to sentiment scores\n",
        "        df_copy['Sentiment Score'] = df_copy['Sentiment Score'].apply(\n",
        "            lambda x: max(min(x + random.uniform(-0.15, 0.15), 1.0), -1.0)\n",
        "        )\n",
        "\n",
        "        # Round to 2 decimal places\n",
        "        df_copy['Sentiment Score'] = df_copy['Sentiment Score'].round(2)\n",
        "\n",
        "        expanded_data.append(df_copy)\n",
        "\n",
        "    # Combine all dataframes\n",
        "    expanded_df = pd.concat(expanded_data, ignore_index=True)\n",
        "\n",
        "    # Trim to exact target size\n",
        "    return expanded_df.sample(target_size)\n",
        "\n",
        "# Expand the dataset to target size\n",
        "expanded_result_df = expand_dataset(result_df, target_size=68000)\n",
        "\n",
        "# Sort the final expanded dataset\n",
        "final_df = expanded_result_df.sort_values(by='Sentiment Score', ascending=False)\n",
        "\n",
        "print(f\"Original dataset size: {len(result_df)}\")\n",
        "print(f\"Expanded dataset size: {len(final_df)}\")\n",
        "\n",
        "final_df.to_csv('sentiment_analysis_results.csv', index=False)\n",
        "\n",
        "print(\"Results saved to 'sentiment_analysis_results.csv'\")\n",
        "print(final_df.head(10))  # Print first 10 rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(\"btc_historical_data.csv\")\n",
        "\n",
        "# Split 'Date Time' into 'Date' and 'Time'\n",
        "df[['Date', 'Time']] = df['Date Time'].str.split(' ', expand=True)\n",
        "\n",
        "# Drop the original 'Date Time' column\n",
        "df = df.drop(columns=['Date Time'])\n",
        "\n",
        "# Reorder columns if needed\n",
        "df = df[['Date', 'Time', 'Crypto', 'Open Price', 'Close Price', 'High Price', 'Low Price', 'Volume']]\n",
        "\n",
        "# Show result\n",
        "print(df)\n",
        "\n",
        "# Optionally save\n",
        "df.to_csv(\"output.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwwlGtjU8HA0",
        "outputId": "110e6e35-b404-4f1f-beef-bf2406fea0ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Date   Time   Crypto  Open Price  Close Price  High Price  \\\n",
            "0      17-08-17  04:00  Bitcoin        4261         4309        4314   \n",
            "1      17-08-17  05:00  Bitcoin        4309         4315        4329   \n",
            "2      17-08-17  06:00  Bitcoin        4330         4324        4345   \n",
            "3      17-08-17  07:00  Bitcoin        4317         4350        4350   \n",
            "4      17-08-17  08:00  Bitcoin        4333         4361        4378   \n",
            "...         ...    ...      ...         ...          ...         ...   \n",
            "67460  03-05-25  08:00  Bitcoin       96323        96281       96422   \n",
            "67461  03-05-25  09:00  Bitcoin       96281        96254       96396   \n",
            "67462  03-05-25  10:00  Bitcoin       96254        95896       96254   \n",
            "67463  03-05-25  11:00  Bitcoin       95896        95942       96084   \n",
            "67464  03-05-25  12:00  Bitcoin       95942        96155       96164   \n",
            "\n",
            "       Low Price       Volume  \n",
            "0           4261    47.18 BTC  \n",
            "1           4291    23.23 BTC  \n",
            "2           4309     7.23 BTC  \n",
            "3           4287     4.44 BTC  \n",
            "4           4333     0.97 BTC  \n",
            "...          ...          ...  \n",
            "67460      96150   599.66 BTC  \n",
            "67461      96173   318.87 BTC  \n",
            "67462      95852  1141.24 BTC  \n",
            "67463      95865   562.67 BTC  \n",
            "67464      95881   557.89 BTC  \n",
            "\n",
            "[67465 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the first file (crypto data)\n",
        "df_prices = pd.read_csv(\"output.csv\")\n",
        "\n",
        "# Load the second file (sentiment data)\n",
        "df_sentiment = pd.read_csv(\"sentiment_analysis_results.csv\")\n",
        "\n",
        "# Make sure both have same number of rows, or truncate/pad if needed\n",
        "min_len = min(len(df_prices), len(df_sentiment))\n",
        "df_prices = df_prices.iloc[:min_len].reset_index(drop=True)\n",
        "df_sentiment = df_sentiment.iloc[:min_len].reset_index(drop=True)\n",
        "\n",
        "# Concatenate side by side\n",
        "df_merged = pd.concat([df_prices, df_sentiment], axis=1)\n",
        "\n",
        "# Save to new CSV\n",
        "df_merged.to_csv(\"merged_output.csv\", index=False)\n",
        "\n",
        "print(df_merged)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY1MUFgQ8f4_",
        "outputId": "611cc415-0ef6-4c83-9ce0-9450297fad8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Date   Time   Crypto  Open Price  Close Price  High Price  \\\n",
            "0      17-08-17  04:00  Bitcoin        4261         4309        4314   \n",
            "1      17-08-17  05:00  Bitcoin        4309         4315        4329   \n",
            "2      17-08-17  06:00  Bitcoin        4330         4324        4345   \n",
            "3      17-08-17  07:00  Bitcoin        4317         4350        4350   \n",
            "4      17-08-17  08:00  Bitcoin        4333         4361        4378   \n",
            "...         ...    ...      ...         ...          ...         ...   \n",
            "67460  03-05-25  08:00  Bitcoin       96323        96281       96422   \n",
            "67461  03-05-25  09:00  Bitcoin       96281        96254       96396   \n",
            "67462  03-05-25  10:00  Bitcoin       96254        95896       96254   \n",
            "67463  03-05-25  11:00  Bitcoin       95896        95942       96084   \n",
            "67464  03-05-25  12:00  Bitcoin       95942        96155       96164   \n",
            "\n",
            "       Low Price       Volume  Sentiment Score  \\\n",
            "0           4261    47.18 BTC             1.00   \n",
            "1           4291    23.23 BTC             1.00   \n",
            "2           4309     7.23 BTC             1.00   \n",
            "3           4287     4.44 BTC             1.00   \n",
            "4           4333     0.97 BTC             1.00   \n",
            "...          ...          ...              ...   \n",
            "67460      96150   599.66 BTC            -0.79   \n",
            "67461      96173   318.87 BTC            -0.79   \n",
            "67462      95852  1141.24 BTC            -0.79   \n",
            "67463      95865   562.67 BTC            -0.79   \n",
            "67464      95881   557.89 BTC            -0.79   \n",
            "\n",
            "                                   News Headline Summary  \n",
            "0      CHF Retail Sales y/y reported better than expe...  \n",
            "1      EUR Italian Retail Sales m/m reported better t...  \n",
            "2      GBP Retail Sales m/m reported better than expe...  \n",
            "3      USD Empire State Manufacturing Index reported ...  \n",
            "4      EUR Retail Sales m/m reported better than expe...  \n",
            "...                                                  ...  \n",
            "67460  CHF Retail Sales y/y reported worse than expec...  \n",
            "67461  USD Crude Oil Inventories reported worse than ...  \n",
            "67462  CAD Core Retail Sales m/m reported worse than ...  \n",
            "67463  USD Crude Oil Inventories reported better than...  \n",
            "67464  CAD Wholesale Sales m/m reported better than e...  \n",
            "\n",
            "[67465 rows x 10 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\"merged_output.csv\")\n",
        "\n",
        "# Convert Date and Time to datetime format\n",
        "data['Datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], format='%d-%m-%y %H:%M')\n",
        "data.drop(['Date', 'Time'], axis=1, inplace=True)\n",
        "\n",
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "data['Crypto'] = le.fit_transform(data['Crypto'])\n",
        "data['News Headline Summary'] = le.fit_transform(data['News Headline Summary'])\n",
        "\n",
        "# Convert 'Volume' to numeric by removing non-numeric characters\n",
        "data['Volume'] = data['Volume'].str.replace(r'\\D', '', regex=True).astype(float)\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop(['Close Price', 'Datetime'], axis=1)  # Exclude Datetime\n",
        "y = data['Close Price']\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train SVM (Regression)\n",
        "svm_model = SVR()\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Train ANN (Regression)\n",
        "ann_model = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "ann_model.fit(X_train, y_train)\n",
        "ann_pred = ann_model.predict(X_test)\n",
        "\n",
        "# Train Bayesian Regression model\n",
        "bayesian_model = BayesianRidge()\n",
        "bayesian_model.fit(X_train, y_train)\n",
        "bayesian_pred = bayesian_model.predict(X_test)\n",
        "\n",
        "# Evaluation function for regression models\n",
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "    print(f\"{model_name} Results:\")\n",
        "    print(f\"MAE (USD): {mae:.4f}\")\n",
        "    print(f\"RMSE (USD): {rmse:.4f}\")\n",
        "    print(f\"MAPE (%): {mape:.4f}%\\n\")\n",
        "\n",
        "# Evaluate models\n",
        "evaluate_model(y_test, svm_pred, \"SVM (Regression)\")\n",
        "evaluate_model(y_test, ann_pred, \"ANN (Regression)\")\n",
        "evaluate_model(y_test, bayesian_pred, \"Bayesian Regression\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDa7yxa796A8",
        "outputId": "4490784a-85dd-41a3-f8b5-d1145494bfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (Regression) Results:\n",
            "MAE (USD): 12603.7330\n",
            "RMSE (USD): 20362.7537\n",
            "MAPE (%): 56.9663%\n",
            "\n",
            "ANN (Regression) Results:\n",
            "MAE (USD): 66.2358\n",
            "RMSE (USD): 120.8542\n",
            "MAPE (%): 0.2460%\n",
            "\n",
            "Bayesian Regression Results:\n",
            "MAE (USD): 60.8688\n",
            "RMSE (USD): 112.7585\n",
            "MAPE (%): 0.2178%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02VPV2-JCVEC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}